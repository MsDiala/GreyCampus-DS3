# 10 Examples of Linear Algebra in Machine Learning

    1. Dataset and Data Files
    2. Images and Photographs
    3. One-Hot Encoding
    4. Linear Regression
    5. Regularization
    6. Principal Component Analysis
    7. Singular-Value Decomposition
    8. Latent Semantic Analysis
    9. Recommender Systems
    10. Deep Learning



# 4. Linear Regression

    Linear regression is an old method from statistics for describing the relationships between variables.

    It is often used in machine learning for predicting numerical values in simpler regression problems.

    There are many ways to describe and solve the linear regression problem, i.e. finding a set of coefficients that when multiplied by each of the input variables and added together results in the best prediction of the output variable.

    If you have used a machine learning tool or library, the most common way of solving linear regression is via a least squares optimization that is solved using matrix factorization methods from linear regression, such as an LU decomposition or a singular-value decomposition, or SVD.

    Even the common way of summarizing the linear regression equation uses linear algebra notation:

        y = A . b

    Where y is the output variable A is the dataset and b are the model coefficients.



link[https://machinelearningmastery.com/examples-of-linear-algebra-in-machine-learning/#:~:text=Last%20Updated%20on%20August%209,implementation%20of%20algorithms%20in%20code.]


Diala Yazoury 